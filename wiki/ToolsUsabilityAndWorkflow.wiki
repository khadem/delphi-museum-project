#summary Describes current work to improve tools usability and workflow for deploying Delphi.
[DelphiWikiHome Delphi Wiki Home]
<wiki:toc max_depth="1" />

= Introduction =

The tools began as a set of core capabilities for NLP, text mining, statistical reporting, etc., with a minimal UI to invoke the tools. This required considerable knowledge of the system to be useful, and so was not very user-friendly. We have been working to remedy this with a number of projects, mostly around refactoring code, conducting a simple needs assessment and application redesign, and then looking at other workflow issues (primarily around database access). Notes for this are gathered below.
----
=Reworking Workspace model for Delphi tools(mostly complete)=
_Note: this has mostly be accomplished as of Jan 2009. We reworked the UI to be project based. The tool remembers the most recent project. Projects contain path references to resources, and reload the resources when the project is opened. Menus are now structured around verbs, although it has been difficult to choose menu labels for actions like _{perform the text-mining function on the object metadata to extract the concept-associations for concepts represented in the referenced ontology}_. We also refactored a lot of code to make maintenance easier._

The current Delphi tools require users to load resources in a specific order, with little help on the dependencies. There is also no help on recently opened files, and similar functionality. A major problem is the lack of obvious workflow for a given project.
One idea that has promise is to move to a notion of a project-workspace as the core to the application. In this model, a user would create a project (workspace), and would then specify the pieces (resources) that were to be used. Once these were set, certain operations would be available to run, much like the current (partial) attempts to only enable menus when prerequisites have been met.

Several questions arise:
  * Do we support more than one type of project, or are there just different tasks on a project, constrained by the resources specified? E.g., If there is no ontology specified, but there is a metadata resource, is this a different project (for vocabulary analysis) from a text mining project?
  * Can we save the most recently opened workspace in a settings file? This would be really nice for a host of reasons.

If we make the UI have a project settings page, then we can show all the filepaths and means of setting them. This is instead of the menu-driven means. New Project creates an empty one, requiring a name. Could also allow setting up everything. Need a New Project, Open Project, Save Project. Need to track when the project is dirty, meaning we should change accessors to methods and track dirty state. Prompt to save on exit.

Project settings control all of the resources. Then, have actions to take:
Can we boil these down to just a few actions?
  # Convert Generate and Save (XML) ontology from vocab (deprecated)
  # Export Generate and Save SQL for Ontology (with load variants and incremental)
  # Generate and Save SQL for Objects (with load variants and incremental)
  # Generate and Save SQL for Objects-Concept associations (with load variants and incremental)
  # Analyze Object Info and produce term usage report
  # Analyze Objects-Concept association and produce unused-term usage report. By facet?

Rework menus based upon above. E.g., 
====File====
  * New Project ...
  * Open Project ...
  * Save Project
  * Save Project As ...
  * Exit
====Edit====
  * Cut
  * Copy
  * Paste
====Analyze====
  * Object Info Term Usage (requires !ObjInfo file)
  * Object/Concept Association (requires !ObjInfo file and Ontology. Later with load variants and an option to connect to DB). Incremental? [Do this as wizard that sets options for reporting and output]
====Images====
  * Compute Orientations [Separate export operation]
====Export====
  * Object Info (later with load variants and an option to connect to DB). Incremental?
  * Concept Ontology
    * As XML file
    * As SQL (later with load variants and an option to connect to DB). Incremental?
    * Hooks/Exclusions to SQL (later with load variants and an option to connect to DB). Incremental?
  * Image Paths
    * As SQL Insert Statement
    * As SQL Loadfile (later with option to connect to DB). Incremental?
----
=Reworking Tools to connect directly to databases (in progress)==
There are a number of steps in the workflow that are cumbersome, and require some care from a human to run sql commands or other scripts from the command line. This makes it harder for museum folks to handle the workflow themselves. These steps include:
  # Extracting metadata from the existing CMS database
  # Running filters and noise reduction tools to remove extraneous metadata and to elide certain classes of strings (like currencies).
  # Loading ontology information into a database, including concepts, hooks and exclusions.
  # Loading concept associations (the results of text mining) into a database.

We'll consider each of these in turn, but first will cover some utilities that will be needed for any of this:
==DB Connection configuration==
We need to configure the information about where the DB is, what the database is called, and what the permissions are. Right now, we have tested connections to !MySQL and MSSQL databases (the former is what Delphi uses, and the latter is used by some CMS and DAM systems,  including Extensis Portfolio and Gallery Systems' TMS). For JDBC, the string is fairly straightforward. Here are examples of the two supported protocols:
{{{
"jdbc:mysql://server.domain.edu:1234/dbname?user=dbuser&password=xxx"
"jdbc:sqlserver://169.123.456.789;databaseName=TMS;user=dbuser;password=xxx"
}}}
The "jdbc" string identifies our connection protocol, and is required. The second token identifies the DB type, an also determines the format of the rest of the string. An server must be specified (with a name or IP address). Depending on the DB, you use different parameters to specify the database name, user and password.

Initially, we will just configure this as a string. although later we could expand on this to separately configure the protocol, machine, db, etc. and make it easier for users.
Note that we may not be using the same DB for different functions, especially in the case of the source for object metadata versus the Delphi DBs used.

Note that we may not be using the same DB for different functions, especially in the case of the source for object metadata versus the Delphi DBs used. There are at least four connections we want to maintain:
  # CMS DB for object MD. May be multiples for some systems (e.g., TMS has multiple DBs that store info).
  # Image information DB. May be in Object Info DB, or in a separate DAM.
  # Delphi for ontologies. May be the running Delphi system, or may not
  # Delphi for running system (may be multiple, given tiered !WebFarm scenario).

For 1) we need to describe authentication to CMS and assume we can get at multiple DBs in the CMS. Thus, describe server, protocol, user, password, and configure the DBs when we describe the extraction model (in a separate manner). Raises questions:

  * What is the format of the DB extraction config (XML, DB via form, etc.). Assume XML for now, and that it looks something like !ColConfig.xml.
  * What is the relationship of the DB extraction file to !ColConfig.xml? Assume that we need to have the same set of columns (destinations for DB extraction, sources for MD mining). Can we unify these? E.g., can we describe sources in DB for each column in !ColConfig.xml? Maybe, but it could get messy for those tables/columns in DB that split into various columns depending upon the types. However, rather than naming the columns as strings, we could enforce coherence. !ColConfig validation would require that columns named in DB extraction are defined for processing, and that there is a source defined for each processing column. Implies a unified configuration with two sections:
{{{
<delphiMetadataConfig>
  <dbSourceInfo>
    <dbServerInfo protocol="{mysql,sqlserver}" location="{name or address}" port="any port specifier"
                user="username" passwd="pass" />
    <source>
      <table db="dbname" name="tablename" joinkey="colname">
        <column name="colname" destination="procColName">
          <filter ... />
        </column>
      <table>
    </source>
  </dbSourceInfo>
  <!-- Note that the following is largely as is from ColConfig.xml -->
  <processingInfo>
    <colSep value=","/>
    <encoding value="UTF-8"/>
    <colInfo name="ObjectType">
      ...
    </colInfo>
    ...
  </processingInfo>
</delphiMetadataConfig>
}}}
For the source info, we need to consider a join that produces a set of rows, within which we get columns. The columns are named or indexed, and note that some are from different tables. 

Also, still need to figure out:
  * filters: regexp to disqualify a row
  * qualifiers: regexp to (positively) qualify which rows are selected
  * noise reduction: regexp to remove strings from results
  * obfuscation: regexp to replace strings (like currency values) in results